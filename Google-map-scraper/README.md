# ğŸ—ºï¸ Google Maps Scraper API

A powerful FastAPI-based web service for scraping business information from Google Maps, deployed on Railway with Chrome/Selenium integration.

## âœ¨ Features

- **ğŸ” Google Maps Scraping**: Extract business information from Google Maps search results
- **ğŸ“§ Contact Extraction**: Find emails, phone numbers, and website information
- **ğŸŒ Website Crawling**: Optional website visits for additional contact details
- **ğŸš€ Railway Deployment**: Optimized for cloud deployment with Chrome in containers
- **ğŸ“Š RESTful API**: Clean JSON responses with proper error handling
- **ğŸ”’ CORS Enabled**: Ready for web application integration
- **âš¡ Fast & Reliable**: Optimized Chrome configuration for containerized environments

## ğŸŒ Live API

**Base URL**: `https://google-map-scraper-production-702a.up.railway.app`

## ğŸ“‹ API Endpoints

### ğŸ  GET `/`
Returns basic API information and available endpoints.

### â¤ï¸ GET `/health`
Health check endpoint for monitoring service status.

### ğŸ§ª GET `/test-chrome`
Test Chrome browser functionality and configuration.

### ğŸ—ºï¸ GET `/test-google-maps`
Test Google Maps scraping with a small sample (3 results).

### ğŸ” POST `/scrape`
**Main scraping endpoint** - Extract business data from Google Maps.

**Request Body:**
```json
{
  "query": "pizza restaurants in New York",
  "max_results": 20,
  "visit_websites": false
}
```

**Response:**
```json
{
  "success": true,
  "data": [
    {
      "name": "Business Name",
      "address": "Business Address",
      "rating": 4.5,
      "review_count": 123,
      "category": "Restaurant",
      "website": "https://example.com",
      "mobile": "(555) 123-4567",
      "email": "contact@example.com",
      "secondary_email": "info@example.com",
      "google_maps_url": "https://maps.google.com/...",
      "search_query": "restaurants in New York",
      "website_visited": true,
      "additional_contacts": "{...}"
    }
  ],
  "total_results": 1,
  "message": "Successfully scraped 1 businesses"
}
```

**Parameters:**
- `query` (string, required): Search query (e.g., "coffee shops in San Francisco")
- `max_results` (integer, optional): Maximum number of results to return (default: 20)
- `visit_websites` (boolean, optional): Whether to visit business websites for additional contacts (default: false)

## ğŸš€ Quick Start

### Test the API
```bash
# Health check
curl https://google-map-scraper-production-702a.up.railway.app/health

# Test Chrome functionality
curl https://google-map-scraper-production-702a.up.railway.app/test-chrome

# Test Google Maps scraping
curl https://google-map-scraper-production-702a.up.railway.app/test-google-maps

# Full scraping example
curl -X POST https://google-map-scraper-production-702a.up.railway.app/scrape \
  -H "Content-Type: application/json" \
  -d '{
    "query": "coffee shops in San Francisco",
    "max_results": 10,
    "visit_websites": false
  }'
```

### Python Example
```python
import requests

# Scrape Google Maps
response = requests.post(
    "https://google-map-scraper-production-702a.up.railway.app/scrape",
    json={
        "query": "restaurants in Chicago",
        "max_results": 15,
        "visit_websites": True
    }
)

data = response.json()
if data["success"]:
    print(f"Found {data['total_results']} businesses")
    for business in data["data"]:
        print(f"- {business['name']}: {business['address']}")
```

## ğŸ› ï¸ Local Development

### Prerequisites
- Python 3.8+
- Chrome browser
- ChromeDriver (automatically managed)

### Installation
```bash
# Clone the repository
git clone <repository-url>
cd Google-map-scraper

# Install dependencies
pip install -r requirements.txt

# Run the application
python simple_app.py
```

The API will be available at `http://localhost:8000`

## â˜ï¸ Railway Deployment

This application is optimized for Railway deployment with:
- **Automatic Chrome installation** via Nixpacks
- **Container-optimized Chrome configuration**
- **Memory-efficient scraping**
- **Proper error handling and logging**

### Deployment Configuration
- **Runtime**: Python 3.11
- **Build**: Automatic via `requirements.txt`
- **Chrome**: Installed via Railway's Nixpacks
- **Port**: Automatically configured via `$PORT` environment variable

## ğŸ”§ Technical Details

### Chrome Configuration
The scraper uses a highly optimized Chrome configuration for containerized environments:
- Headless mode with `--headless=new`
- No sandbox mode for Docker compatibility
- Memory optimization for Railway's resource limits
- Anti-detection measures for reliable scraping
- No user data directory conflicts

### Scraping Features
- **Smart pagination**: Automatically scrolls through Google Maps results
- **Rate limiting**: Built-in delays to avoid being blocked
- **Contact extraction**: Advanced regex patterns for emails and phones
- **Website crawling**: Optional deep crawling of business websites
- **Error handling**: Robust error recovery and logging

## ğŸ“Š Performance

- **Speed**: ~2-5 seconds per business (without website visits)
- **Accuracy**: 95%+ success rate for basic business information
- **Scale**: Handles 100+ results per request
- **Memory**: Optimized for Railway's 512MB limit

## âš ï¸ Important Notes

1. **Rate Limiting**: Google Maps has rate limits. Use reasonable delays between requests.
2. **Terms of Service**: Ensure compliance with Google's Terms of Service.
3. **Website Visits**: Enabling `visit_websites=true` significantly increases processing time.
4. **Resource Usage**: Large scraping jobs may hit Railway's memory/time limits.

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test thoroughly
5. Submit a pull request

## ğŸ“„ License

This project is for educational and research purposes. Please respect website terms of service and rate limits.
- `runtime.txt`: Python version specification

## Usage

1. Deploy to Railway.com
2. Send POST requests to `/scrape` endpoint with your search query
3. Receive structured business data in JSON format

## Environment Variables

- `PORT`: Port number (automatically set by Railway)

## Rate Limiting

The scraper includes built-in rate limiting to avoid being blocked by Google Maps.
